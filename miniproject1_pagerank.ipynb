{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# An Analysis of State Relevance on International Affairs through their Relevance in Armed Conflict"
      ],
      "metadata": {
        "id": "0jERZq3TUOwN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A.\n",
        "\n",
        "Analyses of states in terms of their international relevance usually revolve traditional analyses of measures such as their economy, military power, and diplomatic endeavors. This however does not take into account their relation in armed conflict around the world. Participation in conflict is arguably an important measure to take into account. Direct analysis of individual conflicts however is not enough and will not reflect that conflict and the states' involved impact on the international stage."
      ],
      "metadata": {
        "id": "--y8R9JWUP9f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## B.\n",
        "Using the PageRank algorithm we can create a network of states connected via their history of conflict between other states. Through this we can use the PageRank algorithm to determine a state's importance overall. What is solved here is that we do not only analyze local relevance, but rather the importance of state globally."
      ],
      "metadata": {
        "id": "hcmaMjVIUQAB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## C.\n",
        "\n",
        "As mentioned, this will help in providing quantifiable data on a state's global relevance. Through this project we can find states that have the most relevance in terms of armed conflict. Hopefully the data found in this project will coincide with other metrics, as well as provide new insight."
      ],
      "metadata": {
        "id": "HTge3AobUQC7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-886Md3AGFn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from io import BytesIO\n",
        "from zipfile import ZipFile\n",
        "from urllib.request import urlopen\n",
        "\n",
        "zip_url = 'https://ucdp.uu.se/downloads/ucdpprio/ucdp-prio-acd-251-csv.zip'\n",
        "zip_filename = 'ucdp-prio-acd-251-csv.zip'\n",
        "csv_filename = 'UcdpPrioConflict_v25_1.csv'\n",
        "useful_columns = ['side_a', 'side_a_id', 'side_b', 'side_b_id']\n",
        "\n",
        "df = None\n",
        "try:\n",
        "    # Download zip, store as bytes object\n",
        "    zip_data = None\n",
        "    with urlopen(zip_url) as zip_response:\n",
        "        zip_data = BytesIO(zip_response.read())\n",
        "\n",
        "    # Extract csv from zip, store as dataframe\n",
        "    with ZipFile(zip_data, 'r') as zip_file:\n",
        "        with zip_file.open(csv_filename) as csv_file:\n",
        "            df = pd.read_csv(csv_file, usecols=useful_columns)\n",
        "\n",
        "    print(df.head())\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get ids and assemble a list of all links\n",
        "ids_to_indices_dict = {}\n",
        "name_list = []\n",
        "linked_pairs = []\n",
        "for row in df.itertuples():\n",
        "  # Parse str data from csv\n",
        "  side_a_id_list = [int(id_str.strip()) for id_str in row.side_a_id.split(',')]\n",
        "  side_b_id_list = [int(id_str.strip()) for id_str in row.side_b_id.split(',')]\n",
        "\n",
        "  side_a_name_list = [name_str.strip() for name_str in row.side_a.split(',')]\n",
        "  side_b_name_list = [name_str.strip() for name_str in row.side_b.split(',')]\n",
        "\n",
        "  for i in range(len(side_a_id_list)):\n",
        "      id_a = side_a_id_list[i]\n",
        "      if id_a not in ids_to_indices_dict:\n",
        "          ids_to_indices_dict[id_a] = len(ids_to_indices_dict)\n",
        "          name_a = side_a_name_list[i]\n",
        "          name_list.append(name_a)\n",
        "\n",
        "      for j in range(len(side_b_id_list)):\n",
        "          id_b = side_b_id_list[j]\n",
        "          if id_b not in ids_to_indices_dict:\n",
        "              ids_to_indices_dict[id_b] = len(ids_to_indices_dict)\n",
        "              name_b = side_b_name_list[j]\n",
        "              name_list.append(name_b)\n",
        "\n",
        "          index_a = ids_to_indices_dict[id_a]\n",
        "          index_b = ids_to_indices_dict[id_b]\n",
        "\n",
        "          linked_pairs.append((index_a, index_b))\n",
        "# print(linked_pairs)\n",
        "# print(ids_to_indices_dict)\n",
        "# print(len(linked_pairs))\n",
        "# print(len(ids_to_indices_dict))\n",
        "\n",
        "# Assemble adjacency matrix using list of links.\n",
        "n = len(ids_to_indices_dict)\n",
        "adj_matrix = np.zeros((n, n), dtype=int)\n",
        "for pair in linked_pairs:\n",
        "  # Boolean OR both sides of the link to 1.\n",
        "  adj_matrix[pair[0], pair[1]] = adj_matrix[pair[0], pair[1]] | 1\n",
        "  adj_matrix[pair[1], pair[0]] = adj_matrix[pair[1], pair[0]] | 1\n",
        "print(adj_matrix)"
      ],
      "metadata": {
        "id": "LFpXuh2oDgF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_pagerank(adj_matrix, damping=0.85, max_iters=10000, tolerance=1e-6):\n",
        "    # Normalize the adjacency matrix to ensure that each column sums to 1\n",
        "    adj_matrix = adj_matrix / adj_matrix.sum(axis=0, keepdims=True)\n",
        "\n",
        "    num_pages = adj_matrix.shape[0]\n",
        "\n",
        "    # Initialize the PageRank vector\n",
        "    pagerank = np.ones(num_pages) / num_pages\n",
        "\n",
        "    # Calculate pagerank score iteratively until it converges within tolerance\n",
        "    for iter in range(max_iters):\n",
        "        numerator = 1.0 - damping\n",
        "        denominator = num_pages + damping * adj_matrix @ pagerank\n",
        "        new_pagerank = numerator / denominator\n",
        "\n",
        "        # Check for convergence\n",
        "        if np.linalg.norm(new_pagerank - pagerank, 1) < tolerance:\n",
        "            break\n",
        "\n",
        "        pagerank = new_pagerank\n",
        "\n",
        "    return pagerank\n",
        "\n",
        "result = compute_pagerank(adj_matrix)"
      ],
      "metadata": {
        "id": "NkoY0puqLe8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display results\n",
        "sum = 0\n",
        "for i in range(n):\n",
        "  print(f'{name_list[i]}: {result[i]}')\n",
        "  sum += result[i]\n",
        "print(f'\\nOverall sum: {sum}')"
      ],
      "metadata": {
        "id": "n6o_FIfGOqrG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}